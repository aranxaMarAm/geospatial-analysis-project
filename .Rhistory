theme_minimal(base_size = 12) +
theme(legend.position = "bottom")
p2 <- ggplot(coca_lisa) +
geom_sf(aes(fill = cluster), color = "white", size = 0.05) +
scale_fill_manual(values = lisa_colors, na.value = "grey90") +
labs(title = "LISA Clusters: H_coca (Coca Cultivation)", fill = "Cluster Type") +
theme_minimal(base_size = 12) +
theme(legend.position = "bottom")
# Display side-by-side
grid.arrange(p1, p2, ncol = 2)
# Define color palette
lisa_colors <- c(
"High-High" = "#B2182B",   # dark red
"Low-Low"   = "#2166AC",   # dark blue
"High-Low"  = "#762A83",   # purple
"Low-High"  = "#1B9E77"    # teal
)
p1 <- ggplot(iica_lisa) +
geom_sf(aes(fill = cluster), color = "white", size = 0.05) +
scale_fill_manual(values = lisa_colors, na.value = "grey90") +
labs(title = "LISA Clusters: iica (Conflict Intensity)", fill = "Cluster Type") +
theme_minimal(base_size = 12) +
theme(legend.position = "bottom")
p2 <- ggplot(coca_lisa) +
geom_sf(aes(fill = cluster), color = "white", size = 0.05) +
scale_fill_manual(values = lisa_colors, na.value = "grey90") +
labs(title = "LISA Clusters: H_coca (Coca Cultivation)", fill = "Cluster Type") +
theme_minimal(base_size = 12) +
theme(legend.position = "bottom")
# Display side-by-side
grid.arrange(p1, p2, ncol = 2)
hist(joined_sf$iica, nclass=50)
hist(log(df$median_valueE), nclass=50)
hist(log(joined_sf$iica), nclass=50)
View(joined_sf)
View(joined_sf)
# first we again define the neighbors
# in this case, we consider direct neigbors
nb <- poly2nb(joined_sf, queen = TRUE)
# the we create weights for the neighbors with style: row standardized
nbw <- nb2listw(nb, style = "W", zero.policy = T)
# we set our hypothesis to: alternative to "greater", which means we expect positive autocorrelation
gmoran <- moran.test(joined_sf$iica, nbw,
alternative = "greater")
gmoran
mp <- moran.plot(joined_clean$iica, nbw, labels=F)
mp
# spatially lagged values: mp$wx
# this is our initial regression model
formula <- formula(log(joined_sf$iica) ~ joined_sf$gdp_pc + joined_sf$H_coca + joined_sf$fisc_perf +  joined_sf$e_desplaza)
model1 <- lm(formula = formula, data = df)
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_sf)
# Filter out missing data
joined_clean_coca <- joined_sf %>%
filter(!is.na(H_coca))
# Create neighbors and weights
nb_coca <- poly2nb(joined_clean_coca)
lw_coca <- nb2listw(nb_coca, style = "W", zero.policy = TRUE)
# Standardize the variable
coca_std <- scale(joined_clean_coca$H_coca)
# Create lagged values
lag_coca <- lag.listw(lw_coca, coca_std)  ## checar para después
# Plot Moran scatter
plot(coca_std, lag_coca,
xlab = "H_coca (standardized)",
ylab = "Spatial lag of H_coca",
main = "Moran Scatter Plot for H_coca")
abline(h = 0, v = 0, col = "gray")
abline(lm(lag_coca ~ coca_std), col = "red")
# Filter out missing data
joined_clean_coca <- joined_sf %>%
filter(!is.na(H_coca))
# Create neighbors and weights
nb_coca <- poly2nb(joined_clean_coca)
lw_coca <- nb2listw(nb_coca, style = "W", zero.policy = TRUE)
# Standardize the variable
coca_std <- scale(joined_clean_coca$H_coca)
# Create lagged values
lag_coca <- lag.listw(lw_coca, coca_std)  ## checar para después
# Plot Moran scatter
plot(coca_std, lag_coca,
xlab = "H_coca (standardized)",
ylab = "Spatial lag of H_coca",
main = "Moran Scatter Plot for H_coca")
abline(h = 0, v = 0, col = "gray")
abline(lm(lag_coca ~ coca_std), col = "red")
local_coca <- localmoran(joined_clean_coca$H_coca, lw_coca, zero.policy = TRUE)
# Store results
joined_clean_coca$Ii <- local_coca[,1]
joined_clean_coca$p_Ii <- local_coca[,5]
mean_coca <- mean(joined_clean_coca$H_coca, na.rm = TRUE)
mean_lag_coca <- mean(lag.listw(lw_coca, joined_clean_coca$H_coca), na.rm = TRUE)
joined_clean_coca$quadrant <- NA
joined_clean_coca$quadrant[
joined_clean_coca$H_coca >= mean_coca & lag.listw(lw_coca, joined_clean_coca$H_coca) >= mean_lag_coca
] <- "High-High"
joined_clean_coca$quadrant[
joined_clean_coca$H_coca <= mean_coca & lag.listw(lw_coca, joined_clean_coca$H_coca) <= mean_lag_coca
] <- "Low-Low"
joined_clean_coca$quadrant[
joined_clean_coca$H_coca >= mean_coca & lag.listw(lw_coca, joined_clean_coca$H_coca) <= mean_lag_coca
] <- "High-Low"
joined_clean_coca$quadrant[
joined_clean_coca$H_coca <= mean_coca & lag.listw(lw_coca, joined_clean_coca$H_coca) >= mean_lag_coca
] <- "Low-High"
# Only show significant clusters
joined_clean_coca$quadrant[joined_clean_coca$p_Ii > 0.05] <- NA
mp <- moran.plot(joined_clean$iica, nbw, labels=F)
mp
# spatially lagged values: mp$wx
lmoran <- localmoran(unemployment$s1, nbw, alternative = "two.sided")
lmoran <- localmoran(joined_clean$iica, nbw, alternative = "two.sided")
head(lmoran)
unemployment$lmI <- lmoran[, "Ii"] # local Moran's I
joined_clean$lmI <- lmoran[, "Ii"] # local Moran's I
# p-values corresponding to alternative greater
joined_clean$lmp <- lmoran[, "Pr(z != E(Ii))"]
joined_clean$lmI_sign <- joined_clean$lmI
joined_clean[joined_clean$lmp >= 0.05, "lmI_sign"] <- NA
joined_clean$lmI <- lmoran[, "Ii"] # local Moran's I
# p-values corresponding to alternative greater
joined_clean$lmp <- lmoran[, "Pr(z != E(Ii))"]
joined_clean$lmI_sign <- joined_clean$lmI
joined_clean[joined_clean$lmp >= 0.05, "lmI_sign"] <- NA
joined_clean$lmI <- lmoran[, "Ii"] # local Moran's I
# p-values corresponding to alternative greater
joined_clean$lmp <- lmoran[, "Pr(z != E(Ii))"]
joined_clean$lmI_sign <- joined_clean$lmI
joined_clean[joined_clean$lmp >= 0.05, "lmI_sign"] <- NA
joined_clean$lmI <- lmoran[, "Ii"] # local Moran's I
# p-values corresponding to alternative greater
joined_clean$lmp <- lmoran[, "Pr(z != E(Ii))"]
joined_clean$lmI_sign <- joined_clean$lmI
#joined_clean[joined_clean$lmp >= 0.05, "lmI_sign"] <- NA
qtm(joined_clean, fill="lmI_sign")
tm_shape(joined_clean) +
tm_polygons(
fill = "lmI_sign",
fill.legend = tm_legend(title = "spatial autocorrelation"),
fill.scale=tm_scale(
breaks = c(min(joined_clean$lmI_sign, na.rm=T), 0, max(joined_clean$lmI_sign, na.rm=T)),
labels = c("Negative SAC","Positive SAC"),
textNA = "not significant")
)
lmoran <- localmoran(joined_sf$iica, nbw, alternative = "two.sided")
head(lmoran)
joined_sf$lmI <- lmoran[, "Ii"] # local Moran's I
# p-values corresponding to alternative greater
joined_sf$lmp <- lmoran[, "Pr(z != E(Ii))"]
joined_sf$lmI_sign <- joined_clean$lmI
#joined_sf[joined_sf$lmp >= 0.05, "lmI_sign"] <- NA
qtm(joined_sf, fill="lmI_sign")
tm_shape(joined_sf) +
tm_polygons(
fill = "lmI_sign",
fill.legend = tm_legend(title = "spatial autocorrelation"),
fill.scale=tm_scale(
breaks = c(min(joined_sf$lmI_sign, na.rm=T), 0, max(joined_sf$lmI_sign, na.rm=T)),
labels = c("Negative SAC","Positive SAC"),
textNA = "not significant")
)
# scale such that mean is 0
#mp <- moran.plot(as.vector(scale(la_income$estimate)), nbw)
# get quadrant information
joined_sf$quadr <- attributes(lmoran)$quadr$mean
levels(joined_sf$quadr) <- c(levels(joined_sf$quadr), "non-significant")
joined_sf[(joined_sf$lmp >= 0.05) & !is.na(joined_sf$lmp), "quadr"] <- "non-significant"
tm_shape(joined_sf) +
tm_polygons(
fill = "quadr",
fill.scale=tm_scale(values = c("blue", "lightpink", "skyblue2", "red", "white"))
)
hist(joined_sf$iica, nclass=50)
hist(log(joined_sf$iica), nclass=50)
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_sf)
# Filter rows without NAs (just in case)
joined_sf <- joined_sf %>%
filter(!is.na(iica))
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_sf)
# Filter rows without NAs (just in case)
joined_sf <- joined_sf %>%
filter(!is.na(iica))
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_sf, na.action = na.omit)
# Filter rows without NAs (just in case)
joined_sf <- joined_sf %>%
filter(!is.na(iica)) %>%
filter(!is.na(gdp_pc)) %>%
filter(!is.na(H_coca)) %>%
filter(!is.na(fisc_perf)) %>%
filter(!is.na(e_desplaza))
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_sf, na.action = na.omit)
# Filter rows without NAs (just in case)
joined_clean <- joined_sf %>%
filter(!is.na(iica)) %>%
filter(!is.na(gdp_pc)) %>%
filter(!is.na(H_coca)) %>%
filter(!is.na(fisc_perf)) %>%
filter(!is.na(e_desplaza))
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_clean, na.action = na.omit)
# Filter rows without NAs (just in case)
joined_clean <- joined_sf %>%
filter(!is.na(iica), iica > 0) %>%
filter(!is.na(gdp_pc)) %>%
filter(!is.na(H_coca)) %>%
filter(!is.na(fisc_perf)) %>%
filter(!is.na(e_desplaza))
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_clean, na.action = na.omit)
summary(model1)
# create list of neighbors
wts <- df |>
poly2nb() |>
nb2listw(style = "W", zero.policy = T)
# create list of neighbors
wts <- joined_clean |>
poly2nb() |>
nb2listw(style = "W", zero.policy = T)
# use Morans I test if there is still autocorrelation in our residuals
moran.test(model1$residuals, wts)
library(ggplot2)
residuals_model1 <- residuals(model1)
lagged_residuals_model1 <- lag.listw(wts, residuals_model1)
res <- data.frame("lagged_residuals"=lagged_residuals_model1, "residuals"=residuals_model1)
ggplot(res, aes(x = residuals, y = lagged_residuals)) +
theme_minimal() +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", color = "red")
# spatially lagged X models
slx_model <- lmSLX(formula, data = df, listw = wts)
# spatially lagged X models
slx_model <- lmSLX(formula, data = joined_clean, listw = wts)
# Check for NAs in spatially lagged variables
lag_vars <- create_WX(model.matrix(formula, joined_clean), listw = wts, prefix = "lag.")
lagged_data <- create_WX(model.matrix(formula, joined_clean), listw = wts, prefix = "lag.")
# Load Packages
library(sf) |> suppressMessages() # for spatial vector data
library(dplyr) |> suppressMessages()
library(tidyr)
library(stringr)
library (terra) # for spatial data analysis with vector and raster data
library(tmap) # for static and interactive maps
library(spdep) # for spatial dependency (session 6)
library(leaflet) # for interactive maps
library(units) |> suppressMessages() # for measurement units in R vectors, matrices and arrays automatic propagation, conversion, derivation and simplification of units
library(giscoR)
library(arrow)
library(jsonlite)
library(geojsonsf)
library(geojsonio)
library(spatialreg)
library(gridExtra)
if (!require("tidycensus", quietly = TRUE)) install.packages("tidycensus")
knitr::opts_chunk$set(echo = TRUE)
# Load Packages
library(sf) |> suppressMessages() # for spatial vector data
library(dplyr) |> suppressMessages()
library(tidyr)
library(stringr)
library (terra) # for spatial data analysis with vector and raster data
library(tmap) # for static and interactive maps
library(spdep) # for spatial dependency (session 6)
library(leaflet) # for interactive maps
library(units) |> suppressMessages() # for measurement units in R vectors, matrices and arrays automatic propagation, conversion, derivation and simplification of units
library(giscoR)
library(arrow)
library(jsonlite)
library(geojsonsf)
library(geojsonio)
library(spatialreg)
library(gridExtra)
if (!require("tidycensus", quietly = TRUE)) install.packages("tidycensus")
install.packages("arrow")
knitr::opts_chunk$set(echo = TRUE)
# Load Packages
library(sf) |> suppressMessages() # for spatial vector data
library(dplyr) |> suppressMessages()
library(tidyr)
library(stringr)
library (terra) # for spatial data analysis with vector and raster data
library(tmap) # for static and interactive maps
library(spdep) # for spatial dependency (session 6)
library(leaflet) # for interactive maps
library(units) |> suppressMessages() # for measurement units in R vectors, matrices and arrays automatic propagation, conversion, derivation and simplification of units
library(giscoR)
library(arrow)
library(jsonlite)
library(geojsonsf)
library(geojsonio)
library(spatialreg)
library(gridExtra)
if (!require("tidycensus", quietly = TRUE)) install.packages("tidycensus")
# Load data
zip_filename <- "final_df.zip"
csv_filename <- "../final_df.csv"
# Temporary directory
temp_dir <- tempdir()
# Extract the specific CSV file to temp dir
unzip(zipfile = zip_filename, files = csv_filename, exdir = temp_dir)
# Extracted file will retain directory structure, verify exact path:
extracted_file_path <- file.path(temp_dir, csv_filename)
# Normalize path (since "../" could cause issues)
extracted_file_path <- normalizePath(extracted_file_path, mustWork = FALSE)
# Check if extraction succeeded:
if (!file.exists(extracted_file_path)) {
stop("Extraction failed. Check filenames and paths.")
}
# Read the CSV into a dataframe
final_df <- read.csv(extracted_file_path)
# Clean up by deleting the file
file.remove(extracted_file_path)
head(final_df)
head(final_df)
# Read GeoJSON
muni_sf <- geojson_sf("colombia_municipios_poblacion.json")
head(muni_sf)
## Assigning manually the Coordinate Reference System (CRS)
st_crs(muni_sf) <- 4326
# Check number of geometries in original shapefile
nrow(muni_sf)
# Check number of records in final_df
nrow(final_df)
# Check join key overlap
length(intersect(muni_sf$MPIO_CDPMP, final_df$codmpio))
# Convert both codes to character to ensure matching works
final_df <- final_df %>%
mutate(codmpio = as.character(codmpio))
muni_sf <- muni_sf %>%
mutate(MPIO_CCDGO = as.character(MPIO_CDPMP))
final_22 <- final_df %>%
filter(year == 2022)
muni_sf <- muni_sf %>%
mutate(MPIO_CCDGO = str_pad(as.character(MPIO_CDPMP), width = 5, pad = "0"))
final_22 <- final_22 %>%
mutate(codmpio = str_pad(as.character(codmpio), width = 5, pad = "0"))
joined_sf <- left_join(muni_sf, final_22, by = c("MPIO_CDPMP" = "codmpio"))
# drop all areas with NA values
joined_sf <- joined_sf |> filter(!is.na(iica))
#S1: unemployment rate in percentage
qtm(joined_sf, fill="iica", fill.scale=tm_scale(values="viridis", n=10))
# first we again define the neighbors
# in this case, we consider direct neigbors
nb <- poly2nb(joined_sf, queen = TRUE)
# the we create weights for the neighbors with style: row standardized
nbw <- nb2listw(nb, style = "W", zero.policy = T)
# we set our hypothesis to: alternative to "greater", which means we expect positive autocorrelation
gmoran <- moran.test(joined_sf$iica, nbw,
alternative = "greater")
gmoran
mp <- moran.plot(joined_clean$iica, nbw, labels=F)
mp <- moran.plot(joined_sf$iica, nbw, labels=F)
mp
# spatially lagged values: mp$wx
lmoran <- localmoran(joined_sf$iica, nbw, alternative = "two.sided")
head(lmoran)
joined_sf$lmI <- lmoran[, "Ii"] # local Moran's I
# p-values corresponding to alternative greater
joined_sf$lmp <- lmoran[, "Pr(z != E(Ii))"]
joined_sf$lmI_sign <- joined_sf$lmI
#joined_sf[joined_sf$lmp >= 0.05, "lmI_sign"] <- NA
qtm(joined_sf, fill="lmI_sign")
tm_shape(joined_sf) +
tm_polygons(
fill = "lmI_sign",
fill.legend = tm_legend(title = "spatial autocorrelation"),
fill.scale=tm_scale(
breaks = c(min(joined_sf$lmI_sign, na.rm=T), 0, max(joined_sf$lmI_sign, na.rm=T)),
labels = c("Negative SAC","Positive SAC"),
textNA = "not significant")
)
# scale such that mean is 0
#mp <- moran.plot(as.vector(scale(la_income$estimate)), nbw)
# get quadrant information
joined_sf$quadr <- attributes(lmoran)$quadr$mean
levels(joined_sf$quadr) <- c(levels(joined_sf$quadr), "non-significant")
joined_sf[(joined_sf$lmp >= 0.05) & !is.na(joined_sf$lmp), "quadr"] <- "non-significant"
# scale such that mean is 0
#mp <- moran.plot(as.vector(scale(la_income$estimate)), nbw)
# get quadrant information
joined_sf$quadr <- attributes(lmoran)$quadr$mean
levels(joined_sf$quadr) <- c(levels(joined_sf$quadr), "non-significant")
joined_sf[(joined_sf$lmp >= 0.05) & !is.na(joined_sf$lmp), "quadr"] <- "non-significant"
tm_shape(joined_sf) +
tm_polygons(
fill = "quadr",
fill.scale=tm_scale(values = c("blue", "lightpink", "skyblue2", "red", "white"))
)
hist(joined_sf$iica, nclass=50)
hist(log(joined_sf$iica), nclass=50)
# Filter rows without NAs (just in case)
joined_clean <- joined_sf %>%
filter(!is.na(iica), iica > 0) %>%
filter(!is.na(gdp_pc)) %>%
filter(!is.na(H_coca)) %>%
filter(!is.na(fisc_perf)) %>%
filter(!is.na(e_desplaza))
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_clean, na.action = na.omit)
summary(model1)
# create list of neighbors
wts <- joined_clean |>
poly2nb() |>
nb2listw(style = "W", zero.policy = T)
# use Morans I test if there is still autocorrelation in our residuals
moran.test(model1$residuals, wts)
library(ggplot2)
residuals_model1 <- residuals(model1)
lagged_residuals_model1 <- lag.listw(wts, residuals_model1)
res <- data.frame("lagged_residuals"=lagged_residuals_model1, "residuals"=residuals_model1)
ggplot(res, aes(x = residuals, y = lagged_residuals)) +
theme_minimal() +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", color = "red")
# Check for NAs in spatially lagged variables
lag_vars <- create_WX(model.matrix(formula, joined_clean), listw = wts, prefix = "lag.")
# Identify complete rows in the independent variables
vars_used <- all.vars(formula)[-1]  # drop dependent variable
joined_clean$complete_case <- complete.cases(joined_clean[, vars_used])
# Temporarily drop the geometry for checking missing values
joined_clean_df <- st_drop_geometry(joined_clean)
# Extract variable names used in the formula (excluding the response variable)
vars_used <- all.vars(formula)[-1]
# Check structure
str(joined_clean_df[vars_used])
# Mark rows that have complete data for the independent variables
joined_clean$complete_case <- complete.cases(joined_clean_df[vars_used])
library(spdep)
# Neighborhood list
nb <- listw2nb(wts)
# spatially lagged X models
slx_model <- lmSLX(formula, data = df, listw = wts)
# spatially lagged X models
slx_model <- lmSLX(formula, data = joined_clean, listw = wts)
# spatially lagged X models
slx_model <- lmSLX(formula, data = joined_clean, listw = wts)
joined_clean2 <- joined_clean |>
na.omit()
# create list of neighbors
wts <- joined_clean2 |>
poly2nb() |>
nb2listw(style = "W", zero.policy = T)
# use Morans I test if there is still autocorrelation in our residuals
moran.test(model1$residuals, wts)
# Filter rows without NAs (just in case)
joined_clean <- joined_sf %>%
filter(!is.na(iica), iica > 0) %>%
filter(!is.na(gdp_pc)) %>%
filter(!is.na(H_coca)) %>%
filter(!is.na(fisc_perf)) %>%
filter(!is.na(e_desplaza))
joined_clean2 <- joined_clean |>
na.omit()
# this is our initial regression model
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
model1 <- lm(formula = formula, data = joined_clean2, na.action = na.omit)
summary(model1)
# create list of neighbors
wts <- joined_clean2 |>
poly2nb() |>
nb2listw(style = "W", zero.policy = T)
# use Morans I test if there is still autocorrelation in our residuals
moran.test(model1$residuals, wts)
library(ggplot2)
residuals_model1 <- residuals(model1)
lagged_residuals_model1 <- lag.listw(wts, residuals_model1)
res <- data.frame("lagged_residuals"=lagged_residuals_model1, "residuals"=residuals_model1)
ggplot(res, aes(x = residuals, y = lagged_residuals)) +
theme_minimal() +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", color = "red")
# spatially lagged X models
slx_model <- lmSLX(formula, data = joined_clean, listw = wts)
# spatially lagged X models
slx_model <- lmSLX(formula, data = joined_clean2, listw = wts)
# create list of neighbors
wts <- joined_clean |>
poly2nb() |>
nb2listw(style = "W", zero.policy = T)
# use Morans I test if there is still autocorrelation in our residuals
moran.test(model1$residuals, wts)
model1 <- lm(formula = formula, data = joined_clean, na.action = na.omit)
summary(model1)
wts <- joined_clean |>
poly2nb() |>
nb2listw(style = "W", zero.policy = T)
# use Morans I test if there is still autocorrelation in our residuals
moran.test(model1$residuals, wts)
# spatially lagged X models
slx_model <- lmSLX(formula, data = joined_clean2, listw = wts)
# spatially lagged X models
slx_model <- lmSLX(formula, data = joined_clean, listw = wts)
vars_used <- all.vars(formula(model1))  # Includes dependent + independent variables
summary(joined_clean[, vars_used])      # Check for NAs, negative values, etc.
class(joined_clean)
library(spatialreg)
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)
# SLX model (includes spatial lags of X variables only)
slx_model <- lmSLX(formula, data = joined_clean, listw = wts, zero.policy = TRUE)
summary(slx_model)
