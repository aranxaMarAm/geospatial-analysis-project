---
title: "Geospatial Final Project"
author: "Aranxa Márquez Ampudia & Milton Mier Santander"
date: "2025-05-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Set up

## Packages to be used

```{r}
# Load Packages

library(sf) |> suppressMessages() # for spatial vector data
library(dplyr) |> suppressMessages()
library(tidyr)
library(stringr)
library (terra) # for spatial data analysis with vector and raster data
library(tmap) # for static and interactive maps
library(spdep) # for spatial dependency (session 6)
library(leaflet) # for interactive maps
library(units) |> suppressMessages() # for measurement units in R vectors, matrices and arrays automatic propagation, conversion, derivation and simplification of units
library(giscoR)
library(arrow)
library(jsonlite)
library(geojsonsf)
library(geojsonio)
library(spatialreg)
library(gridExtra)

library(sf)
sf_use_s2(FALSE)

if (!require("tidycensus", quietly = TRUE)) install.packages("tidycensus") 

```


## Load indicators data 

```{r}
# Load data

zip_filename <- "final_df.zip"
csv_filename <- "../final_df.csv"

# Temporary directory
temp_dir <- tempdir()

# Extract the specific CSV file to temp dir
unzip(zipfile = zip_filename, files = csv_filename, exdir = temp_dir)

# Extracted file will retain directory structure, verify exact path:
extracted_file_path <- file.path(temp_dir, csv_filename)

# Normalize path (since "../" could cause issues)
extracted_file_path <- normalizePath(extracted_file_path, mustWork = FALSE)

# Check if extraction succeeded:
if (!file.exists(extracted_file_path)) {
    stop("Extraction failed. Check filenames and paths.")
}

# Read the CSV into a dataframe
final_df <- read.csv(extracted_file_path)

# Clean up by deleting the file
file.remove(extracted_file_path)
```

```{r}
head(final_df)
```

## Load geospatial data 

```{r}
# Read GeoJSON
muni_sf <- geojson_sf("colombia_municipios_poblacion.json")
head(muni_sf)
```


```{r}
## Assigning manually the Coordinate Reference System (CRS)
st_crs(muni_sf) <- 4326

# Check number of geometries in original shapefile
nrow(muni_sf)

# Check number of records in final_df
nrow(final_df)

# Check join key overlap
length(intersect(muni_sf$MPIO_CDPMP, final_df$codmpio))
```


# Preprocessing

```{r}
# Convert both codes to character to ensure matching works
final_df <- final_df %>%
  mutate(codmpio = as.character(codmpio))

muni_sf <- muni_sf %>%
  mutate(MPIO_CCDGO = as.character(MPIO_CDPMP))
```


## Filter for 2022

```{r}
final_22 <- final_df %>%
  filter(year == 2022)
```


```{r}
muni_sf <- muni_sf %>%
  mutate(MPIO_CCDGO = str_pad(as.character(MPIO_CDPMP), width = 5, pad = "0"))

final_22 <- final_22 %>%
  mutate(codmpio = str_pad(as.character(codmpio), width = 5, pad = "0"))
```


## Join datasets

```{r}
joined_sf <- left_join(muni_sf, final_22, by = c("MPIO_CDPMP" = "codmpio"))
```


# Spatial Autocorrelation

## Handling missing values
```{r}
# drop all areas with NA values
joined_sf <- joined_sf |> filter(!is.na(iica))
  
#S1: unemployment rate in percentage
qtm(joined_sf, fill="iica", fill.scale=tm_scale(values="viridis", n=10))
```

## Moran's I Test

```{r}
# first we again define the neighbors
# in this case, we consider direct neighbors
nb <- poly2nb(joined_sf, queen = TRUE)

# the we create weights for the neighbors with style: row standardized
nbw <- nb2listw(nb, style = "W", zero.policy = T)

# we set our hypothesis to: alternative to "greater", which means we expect positive autocorrelation
gmoran <- moran.test(joined_sf$iica, nbw,
                     alternative = "greater")

gmoran
```


```{r}
mp <- moran.plot(joined_sf$iica, nbw, labels=F)
mp
# spatially lagged values: mp$wx
```

## Local Moran's I

Now let's look at the local Moran's I using the `localmoran()` function:

```{r moransI-local}
lmoran <- localmoran(joined_sf$iica, nbw, alternative = "two.sided")
head(lmoran)
```


We now display results for the two-sided test (H1: positive or negative spatial autocorrelation), only considering p values below 0.05 as significant.

```{r moransI-local-map}
joined_sf$lmI <- lmoran[, "Ii"] # local Moran's I
# p-values corresponding to alternative greater
joined_sf$lmp <- lmoran[, "Pr(z != E(Ii))"]
joined_sf$lmI_sign <- joined_sf$lmI
#joined_sf[joined_sf$lmp >= 0.05, "lmI_sign"] <- NA

qtm(joined_sf, fill="lmI_sign")

tm_shape(joined_sf) + 
  tm_polygons(
  fill = "lmI_sign",
  fill.legend = tm_legend(title = "spatial autocorrelation"),
  fill.scale=tm_scale(
    breaks = c(min(joined_sf$lmI_sign, na.rm=T), 0, max(joined_sf$lmI_sign, na.rm=T)),
    labels = c("Negative SAC","Positive SAC"),
    textNA = "not significant")
  )
```


## Identifying Clusters

Local Moran’s I allows us to identify clusters of the following types:

-   High-High: areas of high values with neighbors of high values,
-   High-Low: areas of high values with neighbors of low values,
-   Low-High: areas of low values with neighbors of high values,
-   Low-Low: areas of low values with neighbors of low values.

```{r moransI-local-clusters}

# scale such that mean is 0
#mp <- moran.plot(as.vector(scale(la_income$estimate)), nbw)

# get quadrant information
joined_sf$quadr <- attributes(lmoran)$quadr$mean
levels(joined_sf$quadr) <- c(levels(joined_sf$quadr), "non-significant")
joined_sf[(joined_sf$lmp >= 0.05) & !is.na(joined_sf$lmp), "quadr"] <- "non-significant"
```

# Visualisations

## Significant quadrants:
```{r moransI-local-clusters-plot}
tm_shape(joined_sf) + 
  tm_polygons(
    fill = "quadr",
    fill.scale=tm_scale(values = c("blue", "lightpink", "skyblue2", "red", "white"))
)
```


## Distribution of the outcome variable

```{r outcome-variable}
hist(joined_sf$iica, nclass=50)
```

```{r outcome-variable-log}
hist(log(joined_sf$iica), nclass=50)
```


# Regression models

## Initial (non-spatial) regression model.

```{r regression-model}
# Filter rows without NAs (just in case)
joined_clean <- joined_sf %>%
  filter(!is.na(iica), iica > 0) %>%
  filter(!is.na(gdp_pc)) %>%
  filter(!is.na(H_coca)) %>%
  filter(!is.na(fisc_perf)) %>%
  filter(!is.na(e_desplaza))  

joined_clean2 <- joined_clean |>
  na.omit()

# this is our initial regression model 
formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)

model1 <- lm(formula = formula, data = joined_clean, na.action = na.omit)
summary(model1)
```


# Spatial autocorrelation

The former assumption of independence of residuals is commonly violated in models that use
spatial data. This is because models of spatial processes commonly are characterized
by spatial autocorrelation in the error term, meaning that the model’s performance itself
depends on geographic location. We can assess this using techniques learned in the previous
session such as Moran’s I.


```{r autocorrelation}
# create list of neighbors
wts <- joined_clean |>
  poly2nb() |>
  nb2listw(style = "W", zero.policy = T)

# use Morans I test if there is still autocorrelation in our residuals
moran.test(model1$residuals, wts)
```
```{r residual-dist23}
library(ggplot2)
residuals_model1 <- residuals(model1)
lagged_residuals_model1 <- lag.listw(wts, residuals_model1)

res <- data.frame("lagged_residuals"=lagged_residuals_model1, "residuals"=residuals_model1)

ggplot(res, aes(x = residuals, y = lagged_residuals)) +
  theme_minimal() +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red")
```

The Moran’s I test statistic is modest and positive (0.204) but is statistically significant.

Therefore, we need models that can account for such spatial autocorrelation.

# Spatial regression

There are three simple models that accommodate spatial effects slightly different. The first is the spatially lagged X models:

## 1. Spatially lagged X models 

```{r slx}
vars_used <- all.vars(formula(model1))  # Includes dependent + independent variables
summary(joined_clean[, vars_used])      # Check for NAs, negative values, etc.

class(joined_clean)
# Should include "sf"

library(spatialreg)

formula <- formula(log(iica) ~ gdp_pc + H_coca + fisc_perf + e_desplaza)

# SLX model (includes spatial lags of X variables only)
slx_model <- lmSLX(formula, data = joined_clean, listw = wts, zero.policy = TRUE)
summary(slx_model)
```
You can see now, that there are coefficient estimates for the covariates and the *lagged* covariates.

We need to be careful in the interpretation of coefficients, as there are *direct* and *indirect* effects.
This we can therefore look at the `impacts`:

```{r slx-impact}
summary(impacts(slx_model))
```

We can rerun Moran's I to test if there is still autocorrelation in the residuals:

```{r slx-autoregression}
moran.test(slx_model$residuals, wts)
```
As Moran's I still shows significant autocorrelation, we should assume that we have not yet captured the spatial dependence sufficiently with our model.


### 2. Spatial lag models

Spatial lag models account for spatial dependence by including a spatial lag of the outcome variable in the model.
In doing so, it accounts for spatial spillover effects – the possibility
that outcome values in neighboring areas have an influence on outcome values in a given location.

We can use the `lagsarlm` function of the `spatialreg` package fir Maximum Likelihood (ML) estimation of the spatial lag model:

```{r slm}
# spatial lag models
lag_model <- lagsarlm(
  formula = formula,
  data = joined_clean,
  listw = wts, # taking the same weights as before
  zero.policy = T
  )
summary(lag_model, Nagelkerke = TRUE)
```

The estimated coefficient Rho (0.57) indicates a positive relationship between neighboring values and this value.
It is significant, as indicated by the p-value of the asymptotic standard error.
The fact the lag is significant adds further evidence that this is a better model than the ordinary least squares (OLS) regression specification.


Usually, you would be looking at the R Square and compare models.
Be careful! This R Square is not a real R Square, but a pseudo-R Square and therefore is not comparable to the one we obtain from the OLS regression model.

The Likelihood Ratio test (LR), if significant (as here) indicates that the spatial model is better than the base model *(assesses the goodness of fit of two competing nested statistical models)*.
The Wald test is a similar test.

LM (Lagrange multiplier) test for residual autocorrelation shows that there is no more significant resiudal autocorrelation.

Note that interpretation of the fitted coefficients should use impact measures, because of the feedback loops induced by the data generation process for this model!

Here, we use Monte Carlo simulation to obtain simulated distributions of the various impacts. (As this is a simulation, values are not deterministic)


```{r slm-impacts}

imp <- impacts(lag_model, listw = wts, R=100) # compute impacts
imp
```

```{r slm-impacts2}
#To print the p values
summary(imp, zstats=T)$pzmat
```


Again, we can rerun Moran's I with the model's residuals: 

```{r slm-morans}
moran.test(lag_model$residuals, wts)
```
Now, we do not have significant autocorrelation left, which is a sign that our model now captures the spatial relationship better.

## Spatial error models

In contrast with spatial lag models, spatial error models include a spatial lag in a model’s error term. This is designed to capture latent spatial processes that are not currently being accounted for in the model estimation and in turn show up in the model’s residuals.

```{r sem}
error_model <- errorsarlm(
formula = formula,
data = joined_clean,
listw = wts,
zero.policy = TRUE
)
summary(error_model, Nagelkerke = TRUE)
```







The estimated coefficient Lambda (0.47) indicates a positive relationship between neighboring residuals and this value.
It is significant, as indicated by the p-value of the asymptotic standard error.

Again, this R Square is not a real R Square, but a pseudo-R Square and therefore is not comparable to the one we obtain from the OLS regression model.

Instead, we can look at the Likelihood Ratio test (LR) on this parameter which is significant, indicating a better model than the base model.

Also, we can look at the Akaike Information Criterion (AIC). Generally: the smaller the better.
We see that the error model has an AIC of 511.14 whereas the linear model without spatial dependence has an AIC of 673.06, so this is telling us there is a better fit when we include the spatial error.

Here, we can use the estimated coefficients directly and do not need to look at the impacts.


Again, we can rerun Moran's I with the model's residuals: 

```{r sem-morans}
moran.test(error_model$residuals, wts)
```

As before, with the lag model, there is no significant autocorrelation left. 


### Which model is better?


#### 1. Lagrange multiplier test

We can also use Lagrange multiplier tests to evaluate the appropriateness of these models together. These tests check for spatial error dependence (LMerr), whether a spatially lagged dependent variable is missing (LMlag), and the robustness of each in the presence of the other (RLMerr, RLMlag - RLMerr tests for error dependence in the possible presence of a missing lagged dependent variable, RLMlag the other way round).
The `lm.LMtests()` function can be used with an input linear model to compute these tests.

```{r lagrange}
lm.LMtests(
  model1,
  wts,
  test = c("LMerr", "LMlag")
  # LM error, LM lag
)
```

When both LM test statistics reject the null hypothesis, we need to have a look at the robust version of these tests (Robust LM).
 
 If only one of them are: problem solved. We would choose a spatial lag or a spatial error model according to this (i.e., if the lag LM was significant and the error LM was not we would run a spatial lag model or viceversa).


```{r lagrange_robust}
lm.LMtests(
  model1,
  wts,
  test = c("RLMerr", "RLMlag")
  # robust LM error, robust LM lag
)
```
While both the lag and error models would be appropriate for this data, the test statistic for the robust version of the lag model is larger, suggesting that the spatial lag model should be preferred over the spatial error model in this example.

#### 2. Akaike Information Criterion (AIC)

Another option would be to compare the log likelihood values: -248.57 for the error model, -202.5978 for the lag model.
(The log-likelihood value of a regression model is a way to measure the goodness of fit for a model. The higher the value of the log-likelihood, the better a model fits a dataset.)
However, this is only suitable, if both models have the same number of predictors.

More generally, we can use the Akaike Information Criterion (AIC), which also accounts for the number of estimated parameters in the model.
(AIC deals with the trade-off between the goodness of fit of the model and the simplicity of the model)
The smaller the AIC, the better the fit.


```{r AIC}
AIC(model1, lag_model, error_model)
```
The AIC also suggests that the lag model is a better fit.





```{r}


```



